<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Programming | The Blog from Darel]]></title>
  <link href="http://darelf.github.io/blog/categories/programming/atom.xml" rel="self"/>
  <link href="http://darelf.github.io/"/>
  <updated>2014-03-11T13:33:12-04:00</updated>
  <id>http://darelf.github.io/</id>
  <author>
    <name><![CDATA[Darel Finkbeiner]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Distributed Jobs]]></title>
    <link href="http://darelf.github.io/blog/2014/03/11/distributed-jobs/"/>
    <updated>2014-03-11T13:12:33-04:00</updated>
    <id>http://darelf.github.io/blog/2014/03/11/distributed-jobs</id>
    <content type="html"><![CDATA[<p>This post is supposed to be about network queuing of jobs that can be
distributed into discrete tasks which themselves can be completed in
any order. And about the boiled down <a href="http://github.com/darelf/stream-queue">stream-queue</a>
npm package that I have published. I will diverge just a bit here to
talk a little bit of background.</p>

<!--more-->


<p>STREAMS. Just think about that. Streams. Think of all the things it implies
in programming to talk about streams and streaming.</p>

<p>Probably number one is networking, that is TCP (or whatever) network
sockets that are read/write and have very well-established, at this point,
semantics. Open, close, pause, end, read, write, etc. Depending on the
exact stream, of course, things may be slightly different, and we&rsquo;ve seen
quite a lot of semantics built on top of streams.</p>

<p>Nodejs, of course, does networking really well. In fact, that may be the
number one purpose for most programmers using it. It&rsquo;s just really
fantastic at networking. Your code can worry about what goes on just
above the socket level, with the streams. They also give you an
abstraction, so that there are file streams, etc. helping you out.</p>

<p>This is all fairly normal in programming, and streams have been around
for a long time. UNIX pipes are probably the most common stream-semantic
thing that programmers use, but they are everywhere in just about every
language that&rsquo;s of any use.</p>

<p>So&hellip;</p>

<p>Back to jobs. If you have a big job that can broken down into discreet
tasks such that those tasks can happen in any order, you have something
that can be distributed. And by distributed, I mean among separate processes,
each process accomplishing one of the tasks towards the goal of completing
the job.</p>

<p>What <code>stream-queue</code> is designed to do is give the basic functionality of
a distributed queue that I needed. I need to have it manage the list of
tasks, how many total tasks there were at the beginning, how many have
been completed and how many are left to do. It needs to notify me of
when it starts, when it ends, and each time a step is taken on the way
(progress).</p>

<p>These are all straightforward. They need to not depend on time. That is,
having a unique timestamp should not be required, seeing as how there
might be many workers concurrently processing tasks, and some will inevitably
happen at the same timestamp.</p>

<p>The workers should be able to spin up or shutdown without consequence to
the working of the queue as it is in progress. One future upgrade to the
<code>stream-queue</code> package will be the ability to re-do a task if a worker
gets shutdown before completing the task. Also, having a standard semantic
for asking the queue to shutdown one of its workers, either simply to
reduce the load, or possibly even by name.</p>

<p>Others might be the ability to manage multiple kinds of workers, and
have those workers advertise the kind of work they can do and let the
queue manager distribute jobs accordingly.</p>

<p>So that&rsquo;s where it&rsquo;s at. A lot of interesting tweaks to be made, and a
lot of progress towards better features.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Wrap Those Web Sockets]]></title>
    <link href="http://darelf.github.io/blog/2014/03/04/wrap-those-web-sockets/"/>
    <updated>2014-03-04T10:59:10-05:00</updated>
    <id>http://darelf.github.io/blog/2014/03/04/wrap-those-web-sockets</id>
    <content type="html"><![CDATA[<p>Here&rsquo;s the situation: You have a websocket-friendly routing infrastructure that
only has a single port available on each machine. (at least that you can use) But
you have some awesome client-server stuff that runs completely in the background
and is not really related to browsers or anything. You currently, and brilliantly,
have them speaking over regular node streams using the <code>net</code> functionality.</p>

<p>What to do?</p>

<!--more-->


<p>The routing structure only routes http requests. You can&rsquo;t just redirect regular
socket connections.</p>

<p>WEBSOCKETS TO THE RESCUE!  Websockets are just sockets, but they are negotiated
over http. Oh yeah they are. So they can be routed by your infrastructure that
supports websockets. (like, say, <a href="http://github.com/substack/bouncy">bouncy</a>, but
there are plenty of other examples).</p>

<p>But you aren&rsquo;t using a browser. There&rsquo;s no browser here. Hmm.</p>

<p>You go check out <code>npm</code> and find out that maxogden has already solved your problem.
That&rsquo;s what you do. He has already wrapped websockets with stream functionality in
a project he calls <a href="http://github.com/maxogden/websocket-stream">websocket-stream</a></p>

<p>Now your carefully designed code that leverages the node stream api can continue
on untouched simply by wrapping the websockets with this little gem.</p>

<p>Enjoy!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Building Blocks]]></title>
    <link href="http://darelf.github.io/blog/2014/02/18/building-blocks/"/>
    <updated>2014-02-18T08:04:35-05:00</updated>
    <id>http://darelf.github.io/blog/2014/02/18/building-blocks</id>
    <content type="html"><![CDATA[<p>Modules. Oh, modules.</p>

<p>I&rsquo;ve talked to so many programmers over the years, and the one thing I would suggest
to all of them is to rediscover modules. As opposed to frameworks.</p>

<p>Modules are the building blocks of application development. Keeping them out of
frameworks lets them breath and be more generally useful than if you bind them tightly
in chains. You can reuse modules over and over again, if they are well designed, in
many different contexts only if you emancipate them from the bondage of frameworks.</p>

<!--more-->


<p>What does that even look like?</p>

<p>Let&rsquo;s take a quick overview look at a problem I needed to solve recently: I have a
very large list of items that need processing and each item requires multiple database
queries and even some file access. (large means in the millions)</p>

<p>What did I try?</p>

<p>Well, I tried just looping. That works fine on 10s of thousands of items, but the
asynchronous nature of the database kills that on larger sets. It just fills up the
space and crashes.</p>

<p>Next up was an in memory queue. This actually works, but it is slow. It is slow for
all the obvious reasons, but also because I&rsquo;m using a single process, single thread
solution. This means I have to keep concurrency down because otherwise I will, again,
fill up the available memory or use up the available file handles. ( I actually tried
both the queue from the <code>async</code> module, as well as <code>queue-async</code>. The first would actually
work, while the second was so slow it wasn&rsquo;t even worth pursuing any further. )</p>

<p>So that&rsquo;s what didn&rsquo;t work at the level of performance I wanted, and wouldn&rsquo;t scale
anyway.</p>

<p>Network Queue</p>

<p>What I did was separate the problem even further. I started with an object that knew
how to process the individual items, and one that new how to get lists of items and
queue them up for processing. So I broke that up into a worker, a manager and a server.
This would allow me to scale up as many workers as I wanted, and even put them on
different physical machines if I wanted.</p>

<p>An aside: The good thing, seeing as this is node.js, is that a stream is a stream (for the most
part) and what I did to make it work over the network would just as likely work fine
over other kinds of streams.</p>

<p>Conceptually, there are four parts I considered vital to accomplishing this task (and
any similar task): Completely separate out the code that actually performs the task,
create a worker that only knows how to participate in the group, create a server that
communicates with workers and observers, and an observer that receives updates on what&rsquo;s
happening.</p>

<p>The code that actually runs the task needs to be completely separated from the rest.
In this case, the task was to either delete a document or to create an updated document.
That&rsquo;s all this code does, it knows how to get the information from the database and
update the index.</p>

<p>The code that manages the process keeps a list of workers, and list of observers. These
two lists are very lightweight wrappers around streams. It doesn&rsquo;t need much information
about these, just needs the stream so it can send over information. It also keeps the
list of current items that need processing. It uses this to assign to the list of workers
items until it&rsquo;s empty. The observers can request processing and can receive updates of
status.</p>

<p>The workers have a status (idle or busy) and can send update messages and receive request
to process items. That&rsquo;s pretty much it.</p>

<p>The observer mostly just listens to the server waiting for updates. It can also request
that the entire grid work on a particular problem by sending a message. If no problem
is being worked on currently, then the manager will generate the list of tasks and
then start handing them out.</p>

<p>What&rsquo;s underneath there?</p>

<p>Oh, that&rsquo;s just <a href="http://npmjs.org/package/event-stream">event-stream</a> This thing kind of
does what you think. Or maybe not. It creates a pipeline of processing on streams. That
is, node js streams, which in my case means sockets. Basically it listens for <code>events</code>
on the <code>stream</code> and then takes the steps in the chain, possibly passing it back out to
another stream at the end.</p>

<p>It solves a problem I was going to have to solve anyway, since I wanted to use JSON
to communicate between the processes. This module has all of that, and does just that.
Meaning it takes care of the event streaming so I don&rsquo;t have to, and doesn&rsquo;t do a
whole bunch of unrelated, extraneous stuff that makes it unusable or terribly
interdependent. Basic solution of problem using standard interfaces.</p>

<p>In my case, I pass it the socket, split it and parse it (courtesy of <code>event-stream</code>),
and then do something with the parsed message. I throw away the data after I&rsquo;m done,
since I don&rsquo;t need to pass the messages on.</p>

<p>Ta-Da!</p>

<p>That&rsquo;s all there is to it. Use modules. When designing solutions, design them in modules
and as you refactor make them generically useful if you can. When you use a modular
design you can keep swapping out parts of the implementation without hassle. Something
that can be frustrating if not impossible when using a framework.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Semver]]></title>
    <link href="http://darelf.github.io/blog/2014/02/07/semver/"/>
    <updated>2014-02-07T09:00:27-05:00</updated>
    <id>http://darelf.github.io/blog/2014/02/07/semver</id>
    <content type="html"><![CDATA[<p>Semantic Versioning. Hell yeah.</p>

<p>So here at work we finally settled on a versioning scheme. After literally
years of trying to push versioning in general, and semantic versioning in
particular, we are now implementing.</p>

<!--more-->


<p>What is &ldquo;semantic versioning&rdquo;?</p>

<p>In short, you know those version numbers you see on all those projects
on the internet with version numbers like 1.2.5 or 0.10.21? Yeah. That.</p>

<p>The problem semantic versioning is trying to solve is dependency. Meaning
that an application often depends on other software projects, and those
other software projects often are currently being developed, either to
fix bugs or add features/enhancements.</p>

<p>This can often be referred to as &ldquo;dependency hell&rdquo; since making sure of
which version of what you are using in a project can be a nightmare, taking
into account which set of features you depend on from different projects,
what those projects in turn depend on, etc. You need to distinguish between
a bug fix version increase, a feature add, or API breaking changes. Maybe
a new feature is one you want, or maybe you don&rsquo;t. How do you tell which
version of a project you have?</p>

<p>More importantly, how do you communicate those decisions in the project
you are working on with both the other developers on your team (if any)
and to the consumers of your project?</p>

<p>In comes semver to save the day.</p>

<p>The basic idea of semver is this:  MAJOR.MINOR.PATCH</p>

<p>Additional labels, like &lsquo;-musical&rsquo; or whatever can be added if things get hairy.
But the basic idea should serve.</p>

<p>The MAJOR part of a version is the basic feature set. That is, the API for
every version of that project that starts with the same MAJOR number should
not change. If version 1.0.0 has a function X that takes argument Y, then
that should also be the case for version 1.3.17 and 1.1.5 as well.</p>

<p>The MINOR part of a version are minor changes to the API. Maybe a new
function, or a change to the way a function works. But all of the existing
API at x.0.0 should still be there, even if the actual workings of those
may have changed.</p>

<p>The PATCH part of a version are bug fixes. These should not introduce new
functionality, but rather fix broken or incorrect functionality, or possibly
refactor internal workings without actually changing the input or output
of the functions.</p>

<p>How do we use this at work?</p>

<p>Now this is a specific case, and we are just now moving to use this. The idea
for us is pretty much as described above, however the movement is a little
more deployment specific than it is functionality specific. That is, the
version number, especially the MAJOR and MINOR numbers, will indicate what
deployment level this is at.</p>

<p>So, the MAJOR number will be the &ldquo;this is in production&rdquo; version. This is
the customer facing, being used in real work, version. 1.0.x will be in
production use, 2.0.x will be it&rsquo;s successor, etc.</p>

<p>The MINOR number will be &ldquo;features being tested&rdquo;. So, 1.1.x will NOT be
in production use, but rather will be something that is being tested to
eventually be included in the 2.0.x version.</p>

<p>Again, that&rsquo;s a specific case for us, and not really required by the
semver specification. We find that kind of structure useful for our purposes,
while I&rsquo;m sure your project(s) will have different needs. The main reason
for this kind of versioning is to prevent problems related to what version
of which project is being used in a given context.</p>

<p>For more information on semantic versioning, you can check out their
<a href="http://semver.org">website</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Refactor]]></title>
    <link href="http://darelf.github.io/blog/2014/02/06/refactor/"/>
    <updated>2014-02-06T09:40:06-05:00</updated>
    <id>http://darelf.github.io/blog/2014/02/06/refactor</id>
    <content type="html"><![CDATA[<p>You&rsquo;ve heard of refactoring. Wikipedia has a pretty good <a href="http://en.wikipedia.org/wiki/Code_refactoring">definition</a>.
You have probably done it. You may not have even known it.</p>

<p>I often think of refactoring as the primary job in programming. It cuts to the heart of
what this is all about, and the philosophy of programming in general. Refactoring code well
means being disciplined about code structure in the first place. It is the anti-spaghetti code.
It is the way in which we accomplish those ideals of &ldquo;elegant&rdquo; code.</p>

<!--more-->


<p>So, I thought I would give a recent example of something I worked on. It&rsquo;s a small bit. Which
is the best kind, and goes to the point of the whole thing. The rule I live by is to reduce
the problem into smaller and smaller pieces until it is actually manageable.</p>

<p>My problem was filtering.</p>

<p>Specifically, filtering a list of javascript objects by some items in the keys. Easy one that.
Then, one of the filters needed to check for the existance of some key on some other list of
objects.</p>

<p>In the first pass of this, the filter function was written specifically to the problem we
were trying to solve. Here&rsquo;s an example (although the objects were more complex than this):</p>

<pre><code>var array_1 = [{name: 'Joe'}, {name: 'Jane'}]

var array_2 = [{id: 1, name: 'Jane'}, {id:2, name: 'Jane'}]
</code></pre>

<p>So, the idea is to filter the first array to only include objects whose <code>name</code> attribute is
found in the second array. That is, if we run the filter on this sample, it should return this array:
<code>[{name: 'Jane'}]</code></p>

<p>Again, the first pass of this looked like this:</p>

<pre><code>var new_array = array_1.filter(function(v,i,a) {
    for (i = 0; i &lt; array_2.length; i++) {
        if (array_2[i]['name'] == v['name']) return true
    }
    return false
})
</code></pre>

<p>This is very specific. The name of the key, the fact that <code>array_2</code> needs to be in scope, these
all have to be true when running this. More importantly, such a function that looks for a
match in an array could be very useful in more than one context. It&rsquo;s an obvious (some
would say blindingly so) candidate for refactoring.</p>

<p>Without much ado, here&rsquo;s the refactored version of this that I can now use in other places
where I need similar functionality:</p>

<pre><code>function contains(a, key, value) {
    for (i = 0; i &lt; a.length; i++) {
        if (a[i][key] == value) return true
    }
    return false
}
</code></pre>

<p>Much better! Now I can call this function in order to determine if an array of objects
contains a value on a given key. It&rsquo;s not perfect. And it&rsquo;s specific to an array of
objects, and won&rsquo;t work on flat arrays. It could be made even better or more generic,
though we begin at that point to enter the territory of trade-off value.</p>

<p>This version makes a lot of sense in the context of the application, as that application
uses quite a lot of arrays of objects.</p>

<p>It may seem like a small thing, and it is, but these kind of tiny little refactorings
over the course of an entire application will make the code better, more readable,
and more maintainable. ( The name <code>contains</code> is easy to read and understand what
it&rsquo;s supposed to do )</p>
]]></content>
  </entry>
  
</feed>
